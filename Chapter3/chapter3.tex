\chapter{Θεωρία Πληροφοριών}
\label{chapter:chap3}

\section{Εισαγωγή}
\label{section:sect31}

\indent Σε αυτό το κεφάλαιο γίνεται μια εισαγωγή σε βασικά στοιχεία της θεωρίας πληροφοριών και η επεξήγηση της έννοιας εντροπίας της πληροφορίας. Επίσης θα αναφερθούν αλγόριθμοι συμπίεσης (entropy encoding) καθώς και ο αλγόριθμος k-means που χρησιμοποιήθηκε για την παραγωγή των codebooks.

\section{Εντροπία}
\label{section:sect32}

\indent Η εντροπία κατά Shannon που εισήχθηκε από τον Claude E. Shannon το 1948 είναι η ποσοτικοποίηση της αβεβαιότητας μιας τυχαίας μεταβλητής και συνήθως μετριέται σε bits ή nats \cite{shannon}. Η κύρια ποσότητα που παρέχεται από την εντροπία και είναι χρήσιμη σε εμάς είναι το απόλυτο κάτω όριο μέχρι το οποίο η πληροφορία μιας πηγής μπορεί να συμπιεστεί. Η εντροπία ορίζεται ως $ H(X) = -\sum_{i=1}^{n} p(x_i)*\ log_{b} p(x_i) $  όπου $p(x_i)$ είναι η πιθανότητα του ενδεχομένου $x_i$ και η βάση $b$ ορίζει την μονάδα μέτρησης της εντροπίας. Για την συμπίεση δεδομένων συνήθως χρησιμοποιούμε $b=2$, ώστε να έχουμε την εντροπία εκφρασμένη σε bits.

\indent Για να γίνει κατανοητή η έννοια της εντροπίας θα δοθεί ένα παράδειγμα. Έστω ότι πρέπει να αναπαρασταθεί μια ακολουθία από αριθμούς $x_i \in [0,3] $ σε δυαδικό σύστημα. Επομένως υπάρχουν $n=4$ διαφορετικά ενδεχόμενα που χρειάζονται 2 bits το καθένα για να αναπαρασταθούν τα
$x_i = \begin{bmatrix}
0 & 0 \\
0 & 1 \\
1 & 0 \\
1 & 1
\end{bmatrix} $. Αν τα ενδεχόμενα είναι ισοπίθανα ισχύει ότι $ \forall{x_i}, p(x_i)= 0.25 $ και προκύπτει ότι $ H(X) = 2  bits $. Συνεπώς, δε μπορεί να γίνει περαιτέρω συμπίεση. Αν όμως ισχύει ότι $ p(x_1) = 0.7, p(x_2)=p(x_3)=p(x_4)=0.1 $ τότε έχουμε $ H(X) = 1.35678  bits$ ανά σύμβολο κατά μέσο όρο. Επομένως τα δεδομένα  μπορούν ιδανικά να συμπιεστούν κατά $\frac{(2-1.35678)}{2}\% = 32\%$.

\section{Κωδικοποιητές Εντροπίας}
\label{section:sect33}

\indent Οι μέθοδοι που σήμερα υπάρχουν για συμπίεση καταφέρνουν να έρθουν πολύ κοντά στο όριο που δίνει η εντροπία αλλά δε το φτάνουν. Δύο είναι οι κυρίαρχες μέθοδοι, η μέθοδος Huffman και αυτή της Αριθμητικής Κωδικοποίησης. Η δεύτερη είναι δημοφιλής στο βίντεο με την παραλλαγή της που λέγεται CABAC (Context Adaptive Binary Arithmetic Coding).
\begin{itemize}
  \item Η μέθοδος Huffman έχει την μικρότερη πολυπλοκότητα μεταξύ των δυο, συγκεκριμένα έχει σχεδόν μηδενική πολυπλοκότητα κωδικοποίησης (lookup tables) ενώ η πολυπλοκότητα αποκωδικοποίησης είναι μια πράξη ανά $bit$. Ο αλγόριθμος έχει δύο στάδια, το στάδιο κατασκευής ενός δυαδικού δέντου το οποίο γίνεται μια φορά για κάθε κατανομή πιθανότητας, και σαν επόμενο στάδιο είναι αυτό της κωδικοποίησης όπου τα σύμβολα χρησιμοποιούνται σαν διεύθυνση ενός look up table. Τα περιεχόμενα του είναι οι δυαδικές ακολουθίες που έχουν αντιστοιχηθεί στα φύλλα του δέντρου Huffman. Ο αλγόριθμος κατασκευής του δέντρου βάζει τα ενδεχόμενα σε ένα δυαδικό δέντρο και τους αναθέτει λέξεις με διαφορετικό μήκος. Στόχος είναι το ενδεχόμενο με την μεγαλύτερη πιθανότητα να έχει το μικρότερο μήκος και αυτό με την μικρότερη πιθανότητα το μεγαλύτερο μήκος. Έστω λοιπόν ότι υπάρχουν 5 ενδεχόμενα $x_i$ με πιθανότητες $p(S_0) = 0.5, p(S_1)=p(S_2)=0.2, p(S_3)=p(S_4)=0.05$. Το αντίστοιχο δέντρο Huffman για αυτό το παράδειγμα φαίνεται στο Σχήμα~\ref{fig:huffman}. Η αποδοτικότητα του αλγόριθμου Huffman είναι $ H(X) \leq L_c \leq H(X)+1bit  $ όπου $L_c$ είναι το μέσο μήκος ανά σύμβολο. 
      \begin{figure}[h!]
          \centering
          \includegraphics[width=0.5\textwidth]{chapter3/huffman.jpg}
          \caption{Δέντρο Huffman. \cite{misc:huffman}}
          \label{fig:huffman}
      \end{figure}

\newpage
  \item Η μέθοδος της Αριθμητικής Κωδικοποίησης έχει την μεγαλύτερη πολυπλοκότητα μεταξύ των δύο αλλά μας εξασφαλίζει μια εν γένει καλύτερη συμπίεση από αυτή τού Huffman και αρκετά "κοντά" στο όριο εντροπίας. Ο αλγόριθμος όπως και στον Huffman έχει στόχο να δώσει μεγάλο μήκος στα ενδεχόμενα με την μικρότερη πιθανότητα και μικρό σε αυτά με την μεγαλύτερη. Η διαφορά του με τον Huffman είναι πως δεν κωδικοποιεί ανά σύμβολο αλλά όλο την σειρά συμβόλων σε έναν μοναδικό αριθμό $n \in R$. Για παράδειγμα έστω μια κατανομή με 3 σύμβολα A,B,C και τις πιθανότητες τους $ p(A) = 0.5, p(B) = 0.33, p(C) = 0.17 $ και έστω το μήνυμα που κωδικοποιείται είναι το "BCA" . Στο Σχήμα~\ref{fig:ac} φαίνονται τα βήματα της κωδικοποίησης. Στο πρώτο βήμα έρχεται το B και κωδικοποιείται με τον αριθμό 0b01(x) γιατί έχει το μικρότερο μήκος και βρίσκεται στο [0.5,0.83) οπού x σημαίνει αυθαίρετη ακολουθία από bits. Με αυτόν τον τρόπο συνεχίζουν και τα υπόλοιπα βήματα μέχρι τον αριθμό που αντιστοιχεί στην ακολουθία. Η τυπική υλοποίηση του αλγορίθμου CABAC απαιτεί 50 ως 100 αριθμητικές και λογικές πράξεις για την κωδικοποίηση ή την αποκωδικοποίηση ενός δυαδικού συμβόλου.

      \begin{figure}[ht!]
          \centering
          \includegraphics[width=0.5\textwidth]{chapter3/ac.jpg}
          \caption{Βήματα αριθμητικής κωδικοποίησης. \cite{wiki:arcod}}
          \label{fig:ac}
      \end{figure}
\end{itemize}

\newpage
\section{Αλγόριθμος clustering k-means}
\label{section:sect34}

\indent Άλλο ένα στοιχείο που χρησιμοποιήθηκε σε αυτή την διπλωματική και πηγάζει από την Θεωρία Πληροφοριών είναι ο αλγόριθμος clustering k-means. Είναι ένας επαναληπτικός αλγόριθμος όπου στόχος του είναι να χωρίσει με το ελάχιστο σφάλμα $n$ σημεία σε διάσταση χώρου $R^d$ σε $k$ περιοχές $ k \leq n $ όπως φαίνεται στο Σχήμα~\ref{fig:kmeans}. O αλγόριθμος k-means έχει πολύ μεγάλη υπολογιστική πολυπλοκότητα και ανάγεται στα NP-hard προβλήματα.

\begin{figure}[ht]
  \centering
  \includegraphics[width=0.5\textwidth]{chapter3/kmeans.jpg}
  \caption{k-means με $k=2,d=2,n=100,MSE=284.671$. \cite{misc:kmeans}}
  \label{fig:kmeans}
\end{figure}

\begin{algorithm}[H]
\begin{algorithmic}[1]
\State{Choose initial centers for clusters K;} \label{alg:kmeans:s1}
\While{the clusters are changing}
    \State{Reassign the data points and set $Ktemp=0$;}
    \ForAll{Data points n} \label{alg:kmeans:s4}
        \State{Assign data point $n_i$ to the cluster $k_j$ whose center is closest;} \label{alg:kmeans:s5}
        \State{$Ktemp_j+=n_i$}
    \EndFor
    \State{Update the cluster centers;}
    \For{j:=1 to k step 1}
        \State{$\mathbf{r_j}$ = number of points in $Ktemp_j$;}
        \State{$\mathbf{K_j} = \frac{Ktemp_j}{r_j}$;}
    \EndFor
\EndWhile
\end{algorithmic}
\caption{K-Means pseudo code}
\label{alg:kmeans}
\end{algorithm}

\newpage

\indent Στο Βήμα ~\ref{alg:kmeans:s1} του Αλγορίθμου~\ref{alg:kmeans} γίνεται η αρχικοποίηση είτε με τυχαίο τρόπο
(κάθε cluster παίρνει τιμές από ένα τυχαίο σημείο) είτε με κάποια στρατηγική. Στην παρούσα διπλωματική επιλέχθηκε
η στρατηγική KKZ \cite{kkz} η οποία έχει μεγαλύτερη πολυπλοκότητα από την τυχαία αλλά οδηγεί τον αλγόριθμο k-means
σε μικρότερο σφάλμα. Ο αλγόριθμος αρχικοποίησης παραλληλοποιήθηκε με OpenMP και επιτεύχθηκαν οι επιδόσεις του Πίνακα~\ref{table:kkzspeed}.
Πρέπει να σημειωθεί πως ο KKZ εκτός από τα αρχικά δεδομένα δίνει και τα αποτελέσματα της πρώτης επανάληψης του k-means άρα στον χρόνο της Random προστίθεται και το πρώτο iteration.
Στον Πίνακα~\ref{table:kkziter} φαίνεται η συμπεριφορά του k-means με τυχαία και KKZ αρχικοποίηση και παρατηρείται η κυριαρχία
του KKZ όσο αναφορά το σφάλμα.

\begin{table}[h!]
    \begin{center}
        \begin{tabular}{| l | l | l | l | l |}
        \hline
        Αρχικοποίηση   & 1     & 2      & 4     & 6        \\ \hline
        KKZ            & 90.5  & 63.7   & 42.9  & 36.7     \\ \hline
        Random         & 61.5  & 31.2  & 16.6 & 12.3    \\ \hline
        \hline
        \end{tabular}
    \end{center}
    \caption{Διάρκεια αρχικοποίησης (seconds) για KKZ,Random με 1,2,4,6 threads.}
    \label{table:kkzspeed}
\end{table}

\begin{table}[h!]
    \begin{center}
        \begin{tabular}{| l | l | l | l | l | l || l | l || l | l ||}
        \hline
        Τύπος    & $d$  & $n$      & $k$   & KKZ 5  & Random 5 &  KKZ   & End   & Random & End    \\ \hline
        IntraY   & 16   & 100000   & 65536 & 0.437  & 2.710    &  0.434 & 29    & 2.709  & 9                 \\ \hline
        IntraUV  & 16   & 100000   & 65536 & 0.182  & 0.945    &  0.181 & 33    & 0.944  & 7                 \\ \hline
        InterY   & 16   & 100000   & 65536 & 0.168  & 1.095    &  0.167 & 32    & 1.094  & 10                \\ \hline
        InterUV  & 16   & 100000   & 65536 & 0.071  & 0.464    &  0.071 & 27    & 0.463  & 7                 \\ \hline
        \hline
        \end{tabular}
    \end{center}
    \caption{Συμπεριφορά του k-means για Random,KKZ αρχικοποίηση με $k=65536,d=16,n=100000$
    . Φαίνονται το MSE στην επανάληψη 5 και στο σημείο τερματισμού.}
    \label{table:kkziter}
\end{table}

\indent Η πιο σημαντική βελτιστοποίηση επιτεύχθηκε στο σημείο της αναζήτησης του κοντινότερου cluster στο
Βήμα~\ref{alg:kmeans:s5} του Αλγορίθμου~\ref{alg:kmeans}. Στην απλή εκδοχή του αλγορίθμου για κάθε data point
σαρώνονται όλα τα clusters για να βρεθεί το κοντινότερο (full search). Στην παρούσα διπλωματική, χρησιμοποιήθηκε ο αλγόριθμος
FastNN (Fast Nearest Neighbor) \cite{fastnn} ο οποίος οργανώνει τις αποστάσεις σε ένα δυαδικό δέντρο. Ο FastNN  επιτρέπει να γίνουν περίπου
$ log_{2} k $  αναζητήσεις (πολυπλοκότητα αναζήτησης σε δυαδικό δέντρο), διαφορετικά θα έπρεπε να γίνουν k αναζητήσεις.
Αυτό οδηγεί σε μεγάλη επιτάχυνση του προβλήματος της αναζήτησης που είναι το κύριο σημείο συμφόρησης του αλγορίθμου. Σε
συνδυασμό με την παραλληλοποίηση στο Βήμα~\ref{alg:kmeans:s4} με OpenMP επέτρεψε το τρέξιμο μεγάλων πειράματων σε
εύλογο χρονικό διάστημα. Παραδοσιακά ο αλγόριθμος k-means ο οποίος είναι το απαραίτητο στάδιο για τη χρήση VQ, απαιτούσε τόσο πολύ χρόνο καθιστώντας το ανεφάρμοστο. Στην παρούσα διπλωματική προσπαθήθηκε και σε μεγάλο βαθμό επιτεύχθηκε η χρήση k-means με τον συνδυασμό αλγοριθμικών (FastNN,KKZ) και υπολογιστικών τεχνικών (OpenMP). Οι επιταχύνσεις που επιτεύχθηκαν με την χρήση του FastNN και της OpenMP παρουσιάζονται
στον Πίνακα~\ref{table:fastnn}.

\begin{table}[h!]
    \begin{center}
        \begin{tabular}{| l | l | l | l | l |}
        \hline
        Αναζήτηση   & 1     & 2      & 4     & 6    \\ \hline
        FastNN      & 9.7   & 6.1    & 4.4   & 3.2  \\ \hline
        Simple      & 61.4  & 31.2   & 16.6  & 12.3    \\ \hline
        \hline
        \end{tabular}
    \end{center}
    \caption{Διάρκεια μίας επανάληψης (seconds) για Full Search,FastNN με 1,2,4,6 threads με $k=65536,d=16,n=100000$}
    \label{table:fastnn}
\end{table}

\newpage

\indent Για τα πειράματα της διπλωματικής χρησιμοποιήθηκε o εξοπλισμός με τα ακόλουθα χαρακτηριστικά:
\begin{itemize}
    \item HP Blade Server
    \item OS Microsoft Windows Server 2008 R2 Datacenter.
    \item CPU 2xIntel Xeon E5-2600 @ 2.30Ghz οπού παρείχαν συνολικά 12 Threads + 12 με HyperThreading.
    \item RAM 32GB.
\end{itemize} 